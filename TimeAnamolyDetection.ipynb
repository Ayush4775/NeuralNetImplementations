{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb5DXCif4+VDGvcWZiMFoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush4775/NeuralNetImplementations/blob/main/TimeAnamolyDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdjFs1JaSLWQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_url_root = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
        "\n",
        "df_small_noise_url_suffix = \"artificialNoAnomaly/art_daily_small_noise.csv\"\n",
        "df_small_noise_url = master_url_root + df_small_noise_url_suffix\n",
        "df_small_noise = pd.read_csv(\n",
        "    df_small_noise_url, parse_dates=True, index_col=\"timestamp\"\n",
        ")\n",
        "\n",
        "df_daily_jumpsup_url_suffix = \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
        "df_daily_jumpsup_url = master_url_root + df_daily_jumpsup_url_suffix\n",
        "df_daily_jumpsup = pd.read_csv(\n",
        "    df_daily_jumpsup_url, parse_dates=True, index_col=\"timestamp\"\n",
        ")"
      ],
      "metadata": {
        "id": "V-r1K1gaSOFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_small_noise.head())\n",
        "\n",
        "print(df_daily_jumpsup.head())"
      ],
      "metadata": {
        "id": "R98sk1asSQGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "df_small_noise.plot(legend=False, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v0z7r3hoSR9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YNj21GvSSVPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Normalize and save the mean and std we get,\n",
        "# for normalizing test data.\n",
        "training_mean = df_small_noise.mean()\n",
        "training_std = df_small_noise.std()\n",
        "df_training_value = (df_small_noise - training_mean) / training_std\n",
        "print(\"Number of training samples:\", len(df_training_value))"
      ],
      "metadata": {
        "id": "UjIy2Sx-SXu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 288\n",
        "\n",
        "# Generated training sequences for use in the model.\n",
        "def create_sequences(values, time_steps=TIME_STEPS):\n",
        "    output = []\n",
        "    for i in range(len(values) - time_steps + 1):\n",
        "        output.append(values[i : (i + time_steps)])\n",
        "    return np.stack(output)\n",
        "\n",
        "\n",
        "x_train = create_sequences(df_training_value.values)\n",
        "print(\"Training input shape: \", x_train.shape)"
      ],
      "metadata": {
        "id": "0P9t418MSauR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
        "        layers.Conv1D(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dropout(rate=0.2),\n",
        "        layers.Conv1D(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Conv1DTranspose(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Dropout(rate=0.2),\n",
        "        layers.Conv1DTranspose(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
        "    ]\n",
        ")\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "JjyFs5kkSbWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    x_train,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[\n",
        "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "1AwMdUURSdXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IIp3C1ejSgWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get train MAE loss.\n",
        "x_train_pred = model.predict(x_train)\n",
        "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
        "\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Get reconstruction loss threshold.\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ],
      "metadata": {
        "id": "_b6i4jXLSigI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking how the first sequence is learnt\n",
        "plt.plot(x_train[0])\n",
        "plt.plot(x_train_pred[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k2k4OIBGSlNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test_value = (df_daily_jumpsup - training_mean) / training_std\n",
        "fig, ax = plt.subplots()\n",
        "df_test_value.plot(legend=False, ax=ax)\n",
        "plt.show()\n",
        "\n",
        "# Create sequences from test values.\n",
        "x_test = create_sequences(df_test_value.values)\n",
        "print(\"Test input shape: \", x_test.shape)\n",
        "\n",
        "# Get test MAE loss.\n",
        "x_test_pred = model.predict(x_test)\n",
        "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
        "test_mae_loss = test_mae_loss.reshape((-1))\n",
        "\n",
        "plt.hist(test_mae_loss, bins=50)\n",
        "plt.xlabel(\"test MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "# Detect all the samples which are anomalies.\n",
        "anomalies = test_mae_loss > threshold\n",
        "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
        "print(\"Indices of anomaly samples: \", np.where(anomalies))"
      ],
      "metadata": {
        "id": "vVe-fom3SmdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data i is an anomaly if samples [(i - timesteps + 1) to (i)] are anomalies\n",
        "anomalous_data_indices = []\n",
        "for data_idx in range(TIME_STEPS - 1, len(df_test_value) - TIME_STEPS + 1):\n",
        "    if np.all(anomalies[data_idx - TIME_STEPS + 1 : data_idx]):\n",
        "        anomalous_data_indices.append(data_idx)"
      ],
      "metadata": {
        "id": "7tUm_Sv2SpJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df_daily_jumpsup.iloc[anomalous_data_indices]\n",
        "fig, ax = plt.subplots()\n",
        "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
        "df_subset.plot(legend=False, ax=ax, color=\"r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R7P58psgSrh5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}